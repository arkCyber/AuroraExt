# OpenAI Compatible API

Aurora supports OpenAI Compatible API endpoints. You can use any OpenAI Compatible API endpoint with Aurora.

By default, Aurora supports the following OpenAI Compatible API endpoints:

- OpenAI
- LLaMA.cpp
- LM Studio
- Ollama
- Llamafile
- Fireworks
- Groq
- Together
- OpenRouter
- Google AI
- Mistral
- DeepSeek
- SiliconFlow
- VolcEngine
- TencentCloud
- AlibabaCloud
- Infinigence AI
- Novita AI


## Adding OpenAI Compatible API


1. Click on the Aurora icon on the browser toolbar.

2. Click on the `Settings` icon.

3. Go to the `OpenAI Compatible API` tab.

4. Click on the `Add Provider` button.

5. Select the API from the dropdown. In case it is not listed in the default list, select `Custom` and enter the API URL and API Key.

6. Add API key if required.

7. Click on the `Save` button.


::: info
For Ollama, LM Studio, and Llamafile, you don't need to add any models since Aurora will automatically fetch them from the API.
:::